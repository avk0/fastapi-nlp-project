{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16170\n",
      "16170\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "DB_NAME = \"descriptions1.db\"\n",
    "con = sqlite3.connect(DB_NAME)\n",
    "\n",
    "cur = con.cursor()\n",
    "try:\n",
    "    cur.execute(\"DROP TABLE hh_tokens\") # reset table\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "cur.execute(\"CREATE TABLE hh_tokens(hhid, title, tokens, skills, url)\")\n",
    "con.commit()\n",
    "\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def tokenize(s):\n",
    "    tokens = re.findall(\"[\\/\\-а-яёa-z]+\", s.lower())\n",
    "    filtered = [morph.parse(i)[0].normal_form for i in tokens if i not in stopwords.words(\"russian\")]  # нормализация - лемматизация\n",
    "    return ' '.join(filtered)\n",
    "    \n",
    "df = pd.read_sql_query(\"SELECT * FROM hh_descriptions\", con)\n",
    "print(df.size)\n",
    "df_tokens = df.copy()\n",
    "df_tokens['description'] = df_tokens.apply(lambda row: tokenize(row['description']), axis=1)   # 9min 15s\n",
    "print(df_tokens.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3234"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens.to_sql('hh_tokens', con, if_exists='replace')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часть 2: Векторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "DB_NAME = \"descriptions1.db\"\n",
    "con = sqlite3.connect(DB_NAME)\n",
    "\n",
    "class Vacancies:\n",
    "    def __init__(self, vectorizer_type='tfidf', n_top=10):\n",
    "        self.vectorizer_type = 'tfidf'\n",
    "        self.descriptions_df = pd.read_sql_query(\"SELECT * FROM hh_descriptions\", con)\n",
    "        self.tokens_df = pd.read_sql_query(\"SELECT * FROM hh_tokens\", con)\n",
    "        #countvectorizer = CountVectorizer(analyzer='word',stop_words='english')\n",
    "        #count_wm = countvectorizer.fit_transform(df.description)\n",
    "        #count_tokens = countvectorizer.get_feature_names_out()\n",
    "        #df_countvect = pd.DataFrame(data=count_wm.toarray(), columns=count_tokens)\n",
    "        self.tfidfvectorizer = None\n",
    "        self.tfidf_wm = None\n",
    "        self.tfidf_tokens = None\n",
    "        self.df_tfidfvect = None\n",
    "        self.n_top = n_top\n",
    "\n",
    "    def fit(self):\n",
    "        self.tfidfvectorizer = TfidfVectorizer(analyzer='word', stop_words='english')\n",
    "        self.tfidf_wm = self.tfidfvectorizer.fit_transform(self.descriptions_df.description)\n",
    "        self.tfidf_tokens = self.tfidfvectorizer.get_feature_names_out()\n",
    "        self.df_tfidfvect = pd.DataFrame(data=self.tfidf_wm.toarray(), columns=self.tfidf_tokens)\n",
    "\n",
    "    def _find_top_closest_ids(self, resume_text, ntop):\n",
    "        resume_df = pd.DataFrame(self.tfidfvectorizer.transform([tokenize(resume_text)]).toarray(), columns=self.tfidf_tokens)\n",
    "        df2 = pd.DataFrame(cosine_similarity(self.tfidf_wm, resume_df, dense_output=True), columns=['score'])\n",
    "        closest_ids = df2.sort_values('score', ascending=False).iloc[:ntop]\n",
    "        return closest_ids\n",
    "\n",
    "    def _get_vacs_from_ids(self, ids):\n",
    "        return ids.join(self.descriptions_df, how='inner')[[\"title\", \"description\", \"url\", \"score\"]]\\\n",
    "            .to_json(orient=\"records\", force_ascii=False)\n",
    "    \n",
    "    def get_matching_vacancies(self, resume_text):\n",
    "        ids = self._find_top_closest_ids(resume_text, self.n_top)\n",
    "        res = self._get_vacs_from_ids(ids)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"title\":\"Data Scientist to Armenia\",\"description\":\"We are looking for a Data Scientist to join an international fintech team.Your Role and Responsibilities: • Entities extraction: turning unstructured data into enriched ready datasets.• Collaboration with data science and technology teams, developing features and metrics for data processing• Processing Unstructured and Semi-structured Data• Transforming text data into internal infrastructure by using various algorithmic methods• Data enrichment by applying ML and NLP models Requirements:• Excellent expertise in data science• Understanding of data engineering and software development• \\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bStrong knowledge of machine learning methods and algorithms• Understanding of data structures and algorithms• Python or C++ programming skills We offer:• An international professional team• Relocation package• Work-Life Balance• Medical insurance \\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\",\"url\":\"https:\\\\/\\\\/hh.ru\\\\/vacancy\\\\/73824367\",\"score\":0.1542105768},{\"title\":\"Senior Consultant, Data Scientist, Technology Group\",\"description\":\"Department: IT Advisory, Nur-Sultan and Almaty A Senior Data Scientist would typically work works collaboratively with our business teams and our clients to show the art of the possible and to assess possible value and feasibility of applying data science in order to help solve specific business problems. This could include demoing to prospective clients, developing data strategies, leading feasibility studies, explorative data analysis, delivering minimal viable products or fully fledged projects including putting our models into production either on our own or our client’s environments Requirements:  Completed university degree in Computer Science, Statistics, Engineering or similar technical field A combination of one or more of the following (proficient with programming languages like Python, R, Scala, Java, C++; skills in data engineering technologies like Hadoop, HDFS, Spark, Elasticsearch; SQL and NoSQL databases)  Experience in data, data science, data engineering and\\\\/or other technology related capabilities:  Experience applying advanced analytical techniques to large and varied data sets, generated and flowing at a rapid rate. Sample techniques include, but are not limited to applied machine learning, NLP, collaborative filtering and recommender systems, neural networks (including recurrent, convolutional), event detection and tracking, graph analytics.  Experience with:  Generating and test working hypotheses, prepare and analyze historical data, identify patterns from samples for reporting of trends and support Predictive Analytics Leveraging data visualization techniques and tools to effectively demonstrate patterns, outliers and exceptional conditions in the data Creating performance metrics and tracking processes to measure the effectiveness of Data Science solutions Conceptualizing necessary data governance models to support the technical solution and assure the veracity of the data Operating within the exploratory and experimental aspects of Data Science, e.g. to tease out interesting and previously unknown insights from vast pools of data Working collaboratively with other members of the Data Science and Information Architecture teams to innovate and create compelling data-centric stories and experiences Experience in demonstrating data science consultancy skills, e.g. running hypotheses workshops, mentoring more junior team members, preparing reports and presenting data science results.  Responsibilities:  Build data science assets (aka ‘accelerators’), in line with our global strategy, to ensure we have the platforms and core assets in place to meet market demand. This could also include supporting our continuous improvement process around our own design and development processes e.g. about how we ensure the high quality that our clients require in an efficient manner. As a fast growing highly specialized team, you will be involved in the running and growing of our team, e.g. through coaching colleagues, helping with knowledge management. Support client engagements focused on large data sets and applying advanced analytical techniques, in diverse domains such as retail price optimization, marketing strategies, customer intelligence, financial crime, risk management, smart grids, etc. Develop new, or tailor existing, analytical solutions designed for processing large data sets (e.g. using an Hadoop framework) and by applying advanced analytical techniques (e.g. machine learning, neural networks, NLP, A\\\\/B testing, etc.) Develop big data management and data analytics strategies and roadmaps for their implementation; Planning and organisation skills so as to work with a team, handle demanding clients and multitask effectively   \",\"url\":\"https:\\\\/\\\\/hh.ru\\\\/vacancy\\\\/52581749\",\"score\":0.1265718816},{\"title\":\"MLops engineer\",\"description\":\"Job Description: Mars Pet Nutrition Russia is looking for MLOps who will support our sales, marketing, supply and other internal teams with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. What are we looking for?  Strong knowledge of SQL, Python, ML algorithms and statistical inference Demonstrated experience creating production ML pipelines (training, scoring, leveraging in real-time systems) Experience using cloud platforms and deploying analytics in a production environment Experience visualizing\\\\/presenting data for stakeholders using Tableau\\\\/Power BI\\\\/ggplot\\\\/plotly\\\\/etc. Strong soft skills: communication skill, problem solving, drive to learn and dealing with ambiguity Self-starter who welcomes responsibility, along with the ability to thrive in an evolving organization and an ability to bring structure to unstructured situations Intermediate or higher English level (spoken and written)  What will be your key responsibilities?  Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions. Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies. Assess the effectiveness and accuracy of new data sources and data gathering techniques. Develop custom data models and algorithms to apply to data sets. Use machine learning algorithms to increase and optimize business operations efficiency, revenue generation and other business outcomes. Develop and apply testing framework and test model quality. Coordinate with different functional teams to implement models and monitor outcomes. Develop processes and tools to monitor and analyze model performance and data accuracy. Present modelling results to business audience including senior leadership teams (storytelling) Design, develop, refactor, package, harden, and deploy data products Promote the use of internally built and externally sourced tools through presentation, documentation, and cross-team collaboration Develop tools and automate workflows Translate unstructured inefficiencies and pain points into concrete business and technical requirements  What can you expect from Mars?  Competitive salary Annual bonus Medical insurance 100% sick leave compensation Flexible working hours Additional paid vacation if you work more than 5 years Great educational program that you form by yourself \",\"url\":\"https:\\\\/\\\\/hh.ru\\\\/vacancy\\\\/73324607\",\"score\":0.114566897},{\"title\":\"Data Scientist\",\"description\":\"Requirements:  4+ years of data science experience. Experience and understanding of approaches to data analysis (probability theory and statistics, table data analysis experience); experience with statistical libs like scipy, statsmodels, etc.). Familiarity with machine learning (both supervised and unsupervised) classical models and neural networks and experience with popular frameworks (sklearn, LightGBM, xgboost, keras, pytorch, etc.). Ability to create API for a developed solution (FastAPI, Flask, django rest framework, tensorflow-serving, pytorch-serving, Docker, etc.). Experience with reporting and visualization tools and libs (matplotlib, seaborn, plotly, altair, possibly jupyter notebooks, streamlit, tensorboard, etc.). Intermediate spoken English.  Responsibilities:  Support startups with data science research and development. Participate in internal products development.  Benefits:  Projects in Western Europe and America. Career and professional growth. Product development. Full cycle projects. Corporate-funded training. Benefits. Young and friendly team. Long term full time employment Stable pay. Flexible working hours Mentor\\'s support and guidance to help you grow as a developer. \",\"url\":\"https:\\\\/\\\\/hh.ru\\\\/vacancy\\\\/69162481\",\"score\":0.1049960437},{\"title\":\"Аналитик данных \\\\/ BI аналитик\",\"description\":\"Компания Quillis оказывает услуги в области ИТ-Консалтинга и BI решений. Занимается анализом больших данных и визуализацией результатов исследований. Мы ищем коллегу на роль: Аналитик данных \\\\/ BI аналитик Задачи:  Взаимодействие с Заказчиками, методологами и бизнес-аналитиками для сбора требований Анализ больших объемов данных, выявление выбросов Разработка ETL-процессов Создание дашбордов с помощью BI - инструмента Презентация результатов заказчику Поддержка и оптимизация legacy-кода Поддержка существующих дашбордов Анализ изменений бизнес-процессов и их влияния на проект Сбор, анализ и документирование требований.    Мы ожидаем:  Релевантный опыт работы от 2-х лет Уверенное владение SQL (оконные функции, статистические функции, CTE и т.д.) Умение анализировать данные с помощью Python (Pandas, NumPy) Опыт работы с BI системами (Tableau, Power BI) или умение отлично строить различные графики на Python (seaborn, matplotlib) Умение выявлять, структурировать и документировать требования.    Будет плюсом:  Опыт работы с Jira, Confluence Знание синтаксиса и особенностей форматов XML, JSON, CSV Понимание REST\\\\/SOAP Опыт использования UML, BPMN или других графических нотаций Опыт использования с Postman, Swagger Представление о технологиях разработки клиент-серверных систем с двух- и многоуровневой архитектурой, о технологиях современной веб-разработки Знание основ управления качеством ПО Навыки презентации и публичных выступлений Профильное высшее образование.    Мы предлагаем:  Стать участником команды, создающей продукты и реализующей проекты. Работаем со своими продуктами и используем лучшее ПО в своём классе от мировых производителей. В комфортном офисе с современной техникой и панорамным видом на город в 8 минутах пешком от м. «Дмитровская» или удалённо с гибким началом рабочего дня. Мы ценим вклад каждого нашего сотрудника и даём возможность принимать решения. Будет интересно у нас сложные и значимые проекты, возможность участия в проектах федерального масштаба.    Забота:  ДМС (включая стоматологию, ОНКОзащиту). Подарки сотрудникам и их детям к праздникам. Поддержка в сложных жизненных ситуациях.    Развитие:  Предлагаем программу, позволяющую специалистам перемещаться по карьерной лестнице в рамках компании как вертикально, так и горизонтально. Индивидуальный план развития с ежегодной аттестацией. Участие в конференциях, семинарах, сертификации. Поддержим тебя, если тебе интересно расти. \",\"url\":\"https:\\\\/\\\\/hh.ru\\\\/vacancy\\\\/73015413\",\"score\":0.0995884215},{\"title\":\"Junior+\\\\/pre-middle Data Scientist (дистанционно)\",\"description\":\"О компании DataLouna — сервис предиктивной аналитики по киберспорту. Мы разработали алгоритм на основе машинного обучения, который с вероятностью больше 70% предсказывает исход предстоящего матча по CS:GO. Мы очень быстро развиваемся и нам требуются сильные, целеустремленные программисты в команду. Команда разработки русскоязычная, полностью распределенная. Взаимодействуем через стандартный набор инструментов: Notion, Jira и Gitlab. Задачи  Проектировка и разработка пайплайнов обработки данных Генерация гипотез и проведение экспериментов Построение аналитических отчетов. Построение и улучшение mlflow процессов  Требования  Знание основных фреймворком машинного обучения  scikit-learn pandas\\\\/numpy xgboost\\\\/lightgbm\\\\/catboost automl matplotlib\\\\/plotly\\\\/seaborn   Знание основных принципов программирование. Умение писать чистый код. Минимальное знание python backend. Умение развернуть простой микросервис. Глубокие знания в математическом анализе, линейной алгебре, теории вероятностей Базовые знания игры CS:GO. Желание погрузиться в детали игры команд и игроков.  Предлагаем следующие условия  Достойная оплата труда (обсуждается индивидуально по итогам собеседования) Гибкий рабочий график Удаленная работа Возможность карьерного роста внутри команды  Ключевые навыки table data, automl, catboost, scikit-learn, seaborn, flask, fastapi, docker В отклике При отклике на вакансию просим:  Описать последний большой проект и вашу роль в нем, обязанности Результат проекта Вашу оценку того, как вы справились с поставленными задачами \",\"url\":\"https:\\\\/\\\\/hh.ru\\\\/vacancy\\\\/72567313\",\"score\":0.0946425183},{\"title\":\"Junior+\\\\/pre-middle Data Scientist (дистанционно)\",\"description\":\"О компании DataLouna — сервис предиктивной аналитики по киберспорту. Мы разработали алгоритм на основе машинного обучения, который с вероятностью больше 70% предсказывает исход предстоящего матча по CS:GO. Мы очень быстро развиваемся и нам требуются сильные, целеустремленные программисты в команду. Команда разработки русскоязычная, полностью распределенная. Взаимодействуем через стандартный набор инструментов: Notion, Jira и Gitlab. Задачи  Проектировка и разработка пайплайнов обработки данных Генерация гипотез и проведение экспериментов Построение аналитических отчетов. Построение и улучшение mlflow процессов  Требования  Знание основных фреймворком машинного обучения  scikit-learn pandas\\\\/numpy xgboost\\\\/lightgbm\\\\/catboost automl matplotlib\\\\/plotly\\\\/seaborn   Знание основных принципов программирование. Умение писать чистый код. Минимальное знание python backend. Умение развернуть простой микросервис. Глубокие знания в математическом анализе, линейной алгебре, теории вероятностей Базовые знания игры CS:GO. Желание погрузиться в детали игры команд и игроков.  Предлагаем следующие условия  Достойная оплата труда (обсуждается индивидуально по итогам собеседования) Гибкий рабочий график Удаленная работа Возможность карьерного роста внутри команды  Ключевые навыки table data, automl, catboost, scikit-learn, seaborn, flask, fastapi, docker В отклике При отклике на вакансию просим:  Описать последний большой проект и вашу роль в нем, обязанности Результат проекта Вашу оценку того, как вы справились с поставленными задачами \",\"url\":\"https:\\\\/\\\\/hh.ru\\\\/vacancy\\\\/72567312\",\"score\":0.0946425183},{\"title\":\"Junior+\\\\/pre-middle Data Scientist (дистанционно)\",\"description\":\"О компании DataLouna — сервис предиктивной аналитики по киберспорту. Мы разработали алгоритм на основе машинного обучения, который с вероятностью больше 70% предсказывает исход предстоящего матча по CS:GO. Мы очень быстро развиваемся и нам требуются сильные, целеустремленные программисты в команду. Команда разработки русскоязычная, полностью распределенная. Взаимодействуем через стандартный набор инструментов: Notion, Jira и Gitlab. Задачи  Проектировка и разработка пайплайнов обработки данных Генерация гипотез и проведение экспериментов Построение аналитических отчетов. Построение и улучшение mlflow процессов  Требования  Знание основных фреймворком машинного обучения  scikit-learn pandas\\\\/numpy xgboost\\\\/lightgbm\\\\/catboost automl matplotlib\\\\/plotly\\\\/seaborn   Знание основных принципов программирование. Умение писать чистый код. Минимальное знание python backend. Умение развернуть простой микросервис. Глубокие знания в математическом анализе, линейной алгебре, теории вероятностей Базовые знания игры CS:GO. Желание погрузиться в детали игры команд и игроков.  Предлагаем следующие условия  Достойная оплата труда (обсуждается индивидуально по итогам собеседования) Гибкий рабочий график Удаленная работа Возможность карьерного роста внутри команды  Ключевые навыки table data, automl, catboost, scikit-learn, seaborn, flask, fastapi, docker В отклике При отклике на вакансию просим:  Описать последний большой проект и вашу роль в нем, обязанности Результат проекта Вашу оценку того, как вы справились с поставленными задачами \",\"url\":\"https:\\\\/\\\\/hh.ru\\\\/vacancy\\\\/72567324\",\"score\":0.0946425183},{\"title\":\"Junior+\\\\/pre-middle Data Scientist\",\"description\":\"О компании DataLouna — сервис предиктивной аналитики по киберспорту. Мы разработали алгоритм на основе машинного обучения, который с вероятностью больше 70% предсказывает исход предстоящего матча по CS:GO. Мы очень быстро развиваемся и нам требуются сильные, целеустремленные программисты в команду. Команда разработки русскоязычная, полностью распределенная. Взаимодействуем через стандартный набор инструментов: Notion, Jira и Gitlab. Задачи  Проектировка и разработка пайплайнов обработки данных Генерация гипотез и проведение экспериментов Построение аналитических отчетов. Построение и улучшение mlflow процессов  Требования  Знание основных фреймворком машинного обучения  scikit-learn pandas\\\\/numpy xgboost\\\\/lightgbm\\\\/catboost automl matplotlib\\\\/plotly\\\\/seaborn   Знание основных принципов программирование. Умение писать чистый код. Минимальное знание python backend. Умение развернуть простой микросервис. Глубокие знания в математическом анализе, линейной алгебре, теории вероятностей Базовые знания игры CS:GO. Желание погрузиться в детали игры команд и игроков.  Предлагаем следующие условия  Достойная оплата труда (обсуждается индивидуально по итогам собеседования) Гибкий рабочий график Удаленная работа Возможность карьерного роста внутри команды  Ключевые навыки table data, automl, catboost, scikit-learn, seaborn, flask, fastapi, docker В отклике При отклике на вакансию просим:  Описать последний большой проект и вашу роль в нем, обязанности Результат проекта Вашу оценку того, как вы справились с поставленными задачами \",\"url\":\"https:\\\\/\\\\/hh.ru\\\\/vacancy\\\\/72567320\",\"score\":0.0946425183},{\"title\":\"Junior+\\\\/pre-middle Data Scientist (дистанционно)\",\"description\":\"О компании DataLouna — сервис предиктивной аналитики по киберспорту. Мы разработали алгоритм на основе машинного обучения, который с вероятностью больше 70% предсказывает исход предстоящего матча по CS:GO. Мы очень быстро развиваемся и нам требуются сильные, целеустремленные программисты в команду. Команда разработки русскоязычная, полностью распределенная. Взаимодействуем через стандартный набор инструментов: Notion, Jira и Gitlab. Задачи  Проектировка и разработка пайплайнов обработки данных Генерация гипотез и проведение экспериментов Построение аналитических отчетов. Построение и улучшение mlflow процессов  Требования  Знание основных фреймворком машинного обучения  scikit-learn pandas\\\\/numpy xgboost\\\\/lightgbm\\\\/catboost automl matplotlib\\\\/plotly\\\\/seaborn   Знание основных принципов программирование. Умение писать чистый код. Минимальное знание python backend. Умение развернуть простой микросервис. Глубокие знания в математическом анализе, линейной алгебре, теории вероятностей Базовые знания игры CS:GO. Желание погрузиться в детали игры команд и игроков.  Предлагаем следующие условия  Достойная оплата труда (обсуждается индивидуально по итогам собеседования) Гибкий рабочий график Удаленная работа Возможность карьерного роста внутри команды  Ключевые навыки table data, automl, catboost, scikit-learn, seaborn, flask, fastapi, docker В отклике При отклике на вакансию просим:  Описать последний большой проект и вашу роль в нем, обязанности Результат проекта Вашу оценку того, как вы справились с поставленными задачами \",\"url\":\"https:\\\\/\\\\/hh.ru\\\\/vacancy\\\\/72567315\",\"score\":0.0946425183}]'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_text = 'Data Scientist с опытом работы в проектах по продвинутой аналитике и исследованиях. Успешно реализовал проекты включая промышленные решения \\\n",
    "    для клиентов из различных областей: потребительские товары, ритейл, медицинские приборы и другие. Имеет страсть к автоматизации \\\n",
    "    на основе данных. Европейское гражданство. Разработка, алгоритмы, машинное обучение, проведение интервью\\\n",
    "    Data Science, Leadership, R&D, Machine Learning, Software Developement, Algorithms, Agile, Interviewing \\\n",
    "    Python (numpy, pandas, scipy, sklearn, matplotlib, seaborn, requests), DevOps (Linux, Git, Docker), Cloud (MS Azure, AWS),\\\n",
    "    WEB (Flask, Figma, HTML, CSS), Business Intelligence (Power BI), SQL'\n",
    "\n",
    "vac_model = Vacancies()\n",
    "vac_model.fit()\n",
    "vac_model.get_matching_vacancies(resume_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14f7aba52fd8b0d454e4384c50566c86a06153ede604c4929b6bebae2a42d06a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
